---
title: "Distributed Cox Regression"
author: Balasubramanian Narasimhan
date: '2018-01-01'
bibliography: ../bibtex/ipam2018.bib
link-citations: true
categories: []
tags: []
---



<section id="introduction" class="level2">
<h2>Introduction</h2>
<p>It is only a short way from the toy MLE example to a more useful example using Cox regression.</p>
<p>But first, we need the <code>survival</code> package.</p>
<pre class="r"><code>if (!require(&quot;survival&quot;)) {
    stop(&quot;this vignette requires the survival package&quot;)
}</code></pre>
<p>We generate some simulated data for the purpose of this example. We will have three sites each with patient data (sizes 1000, 500 and 1500) respectively, containing</p>
<ul>
<li><code>sex</code> (0, 1) for male/female</li>
<li><code>age</code> between 40 and 70</li>
<li>a biomarker <code>bm</code></li>
<li>a <code>time</code> to some event of interest</li>
<li>an indicator <code>event</code> which is 1 if an event was observed and 0 otherwise.</li>
</ul>
<p>It is common to fit stratified models using sites as strata since the patient characteristics usually differ from site to site. So the baseline hazards (<code>lambdaT</code>) are different for each site but they share common coefficients (<code>beta.1</code>, <code>beta.2</code> and <code>beta.3</code> for <code>age</code>, <code>sex</code> and <code>bm</code> respy.) for the model. See <span class="citation" data-cites="survival-book">(Terry M. Therneau and Patricia M. Grambsch <a href="#ref-survival-book">2000</a>)</span> by Therneau and Grambsch for details. So our model for each site <span class="math inline">\(i\)</span> is</p>
<p><span class="math display">\[
S(t, age, sex, bm) =
[S_0^i(t)]^{\exp(\beta_1 age + \beta_2 sex + \beta_3 bm)}
\]</span></p>
<pre class="r"><code>sampleSize &lt;- c(n1 = 1000, n2 = 500, n3 = 1500)

set.seed(12345)

beta.1 &lt;- -.015; beta.2 &lt;- .2; beta.3 &lt;- .001;

lambdaT &lt;- c(5, 4, 3)
lambdaC &lt;- 2

coxData &lt;- lapply(seq_along(sampleSize),
                  function(i) {
                      sex &lt;- sample(c(0, 1), size = sampleSize[i], replace = TRUE)
                      age &lt;- sample(40:70, size = sampleSize[i], replace = TRUE)
                      bm &lt;- rnorm(sampleSize[i])
                      trueTime &lt;- rweibull(sampleSize[i],
                                           shape = 1,
                                           scale = lambdaT[i] * exp(beta.1 * age + beta.2 * sex + beta.3 * bm ))
                      censoringTime &lt;- rweibull(sampleSize[i],
                                                shape = 1,
                                                scale = lambdaC)
                      time &lt;- pmin(trueTime, censoringTime)
                      event &lt;- (time == trueTime)
                      data.frame(stratum = i,
                                 sex = sex,
                                 age = age,
                                 bm = bm,
                                 time = time,
                                 event = event)
                  })</code></pre>
<p>So here is a summary of the data for the three sites.</p>
<section id="site-1" class="level3">
<h3>Site 1</h3>
<pre class="r"><code>str(coxData[[1]])</code></pre>
<pre><code>## &#39;data.frame&#39;:    1000 obs. of  6 variables:
##  $ stratum: int  1 1 1 1 1 1 1 1 1 1 ...
##  $ sex    : num  1 1 1 1 0 0 0 1 1 1 ...
##  $ age    : int  42 66 40 50 61 47 45 61 70 69 ...
##  $ bm     : num  1.6775 0.0795 -0.8564 -0.7788 -0.3809 ...
##  $ time   : num  3.42 1.051 0.509 2.868 1.073 ...
##  $ event  : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...</code></pre>
</section>
<section id="site-2" class="level3">
<h3>Site 2</h3>
<pre class="r"><code>str(coxData[[2]])</code></pre>
<pre><code>## &#39;data.frame&#39;:    500 obs. of  6 variables:
##  $ stratum: int  2 2 2 2 2 2 2 2 2 2 ...
##  $ sex    : num  1 0 0 0 0 1 0 1 1 0 ...
##  $ age    : int  67 43 48 47 45 55 52 57 54 69 ...
##  $ bm     : num  -0.225 -0.527 -0.642 1.717 1.323 ...
##  $ time   : num  3.409 0.766 0.075 1.637 0.471 ...
##  $ event  : logi  TRUE TRUE FALSE TRUE FALSE FALSE ...</code></pre>
</section>
<section id="site-3" class="level3">
<h3>Site 3</h3>
<pre class="r"><code>str(coxData[[3]])</code></pre>
<pre><code>## &#39;data.frame&#39;:    1500 obs. of  6 variables:
##  $ stratum: int  3 3 3 3 3 3 3 3 3 3 ...
##  $ sex    : num  1 1 0 0 1 0 0 1 1 0 ...
##  $ age    : int  42 64 42 47 48 43 54 59 52 63 ...
##  $ bm     : num  -0.349 -1.026 -0.907 0.775 -0.95 ...
##  $ time   : num  4.893 1.076 0.37 3.192 0.144 ...
##  $ event  : logi  FALSE TRUE TRUE TRUE FALSE FALSE ...</code></pre>
</section>
</section>
<section id="section" class="level1">
<h1></h1>
</section>
<section id="aggregated-fit" class="level1">
<h1>Aggregated fit</h1>
<p>If the data were all aggregated in one place, it would very simple to fit the model. Below, we row-bind the data from the three sites.</p>
<pre class="r"><code>aggModel &lt;- coxph(formula = Surv(time, event) ~ sex +
                                age + bm + strata(stratum),
                            data = do.call(rbind, coxData))
aggModel</code></pre>
<pre><code>## Call:
## coxph(formula = Surv(time, event) ~ sex + age + bm + strata(stratum), 
##     data = do.call(rbind, coxData))
## 
##         coef exp(coef) se(coef)     z       p
## sex -0.17959   0.83562  0.05069 -3.54  0.0004
## age  0.02009   1.02029  0.00286  7.02 2.1e-12
## bm   0.00682   1.00684  0.02501  0.27  0.7852
## 
## Likelihood ratio test=61.9  on 3 df, p=2.32e-13
## n= 3000, number of events= 1588</code></pre>
<p>Here <code>age</code> and <code>sex</code> are significant, but <code>bm</code> is not. The estimates <span class="math inline">\(\hat{\beta}\)</span> are <code>(-0.180, .020, .007)</code>.</p>
<p>We can also print out the value of the (partial) log-likelihood at the MLE.</p>
<pre class="r"><code>aggModel$loglik</code></pre>
<pre><code>## [1] -9594.620 -9563.676</code></pre>
<p>The first is the value at the parameter value <code>(0, 0, 0)</code> and the last is the value at the MLE.</p>
<section id="distributed-computation" class="level2">
<h2>Distributed Computation</h2>
<p>Assume now that the data <code>coxData</code> is distributed between three sites none of whom want to share actual data among each other or even with a master computation process. They wish to keep their data secret but are willing, together, to provide the sum of their local negative log-likelihoods. They need to do this in a way so that the master process will not be able to associate the contribution to the likelihood from each site.</p>
<p>The overall likelihood function <span class="math inline">\(l(\lambda)\)</span> for the entire data is therefore the sum of the likelihoods at each site: <span class="math inline">\(l(\lambda) = l_1(\lambda)+l_2(\lambda)+l_3(\lambda).\)</span> How can this likelihood be computed while maintaining privacy?</p>
<p>Assuming that every site including the master has access to a homomorphic computation library such as <code>homomorpheR</code>, the likelihood can be computed in a privacy-preserving manner using the following scheme. We use <span class="math inline">\(E(x)\)</span> and <span class="math inline">\(D(x)\)</span> to denote the encrypted and decrypted values of <span class="math inline">\(x\)</span> respectively.</p>
<ol start="0" type="1">
<li>Master generates a public/private key pair. Master distributes the public key to all sites. (The private key is not distributed and kept only by the master.)</li>
<li>Master generates a random offset <span class="math inline">\(r\)</span> to obfuscate the intial likelihood.</li>
<li>Master sends <span class="math inline">\(E(r)\)</span> and a guess <span class="math inline">\(\lambda_0\)</span> to site 1. Note that <span class="math inline">\(\lambda\)</span> is not encrypted.</li>
<li>Site 1 computes <span class="math inline">\(l_1 = l(\lambda_0, y_1)\)</span>, the local likelihood for local data <span class="math inline">\(y_1\)</span> using parameter <span class="math inline">\(\lambda_0\)</span>. It then sends on <span class="math inline">\(\lambda_0\)</span> and <span class="math inline">\(E(r) + E(l_1)\)</span> to site 2.</li>
<li>Site 2 computes <span class="math inline">\(l_2 = l(\lambda_0, y_2)\)</span>, the local likelihood for local data <span class="math inline">\(y_2\)</span> using parameter <span class="math inline">\(\lambda_0\)</span>. It then sends on <span class="math inline">\(\lambda_0\)</span> and <span class="math inline">\(E(r) + E(l_1) + E(l_2)\)</span> to site 3.</li>
<li>Site 3 computes <span class="math inline">\(l_3 = l(\lambda_0, y_3)\)</span>, the local likelihood for local data <span class="math inline">\(y_3\)</span> using parameter <span class="math inline">\(\lambda_0\)</span>. It then sends on <span class="math inline">\(E(r) + E(l_1) + E(l_2) + E(l_3)\)</span> back to master.</li>
<li>Master retrieves <span class="math inline">\(E(r) + E(l_1) + E(l_2) + E(l_3)\)</span> which, due to the homomorphism, is exactly <span class="math inline">\(E(r+l_1+l_2+l_3) = E(r+l).\)</span> So the master computes <span class="math inline">\(D(E(r+l)) - r\)</span> to obtain the value of the overall likelihood at <span class="math inline">\(\lambda_0\)</span>.</li>
<li>Master updates <span class="math inline">\(\lambda_0\)</span> with a new guess <span class="math inline">\(\lambda_1\)</span> and repeats steps 1-5. This process is iterated to convergence. For added security, even steps 0-5 can be repeated, at additional computational cost.</li>
</ol>
<p>This is pictorially shown below.</p>
<p><img src="/post/tutorial/figs/round_robin.png" /></p>
</section>
<section id="implementation" class="level2">
<h2>Implementation</h2>
<p>The above implementation assumes that the encryption and decryption can happen with real numbers which is not the actual situation. Instead, we use rational approximations using a large denominator, <span class="math inline">\(2^{256}\)</span>, say. In the future, of course, we need to build an actual library is built with rigorous algorithms guaranteeing precision and overflow/undeflow detection. For now, this is just an ad hoc implementation.</p>
<p>Also, since we are only using homomorphic additive properties, a partial homomorphic scheme such as the Paillier Encryption system will be sufficient for our computations.</p>
<p>We define a class to encapsulate our sites that will compute the Poisson likelihood on site data given a parameter <span class="math inline">\(\lambda\)</span>. Note how the <code>addNLLAndForward</code> method takes care to split the result into an integer and fractional part while performing the arithmetic operations. (The latter is approximated by a rational number.)</p>
<p>We define a class to encapsulate our sites that will compute the partial log likelihood on site data given a parameter <span class="math inline">\(\beta\)</span>.</p>
<p>In the code below, we exploit, for expository purposes, a feature of <code>coxph</code>: a control parameter can be passed to evaluate the partial likelihood at a given <span class="math inline">\(\beta\)</span> value.</p>
<pre class="r"><code>library(gmp)
library(homomorpheR)
Site &lt;- R6::R6Class(&quot;Site&quot;,
                    private = list(
                        ## name of the site
                        name = NA,
                        ## only master has this, NA for workers
                        privkey = NA,
                        ## local data
                        data = NA,
                        ## The next site in the communication: NA for master
                        nextSite = NA,
                        ## is this the master site?
                        iAmMaster = FALSE,
                        ## intermediate result variable
                        intermediateResult = NA,
                        ## Control variable for cox regression
                        cph.control = NA
                    ),
                    public = list(
                        count = NA,
                        ## Common denominator for approximate real arithmetic
                        den = NA,
                        ## The public key; everyone has this
                        pubkey = NA,
                        initialize = function(name, data, den) {
                            private$name &lt;- name
                            private$data &lt;- data
                            self$den &lt;- den
                            private$cph.control &lt;- replace(coxph.control(), &quot;iter.max&quot;, 0)
                        },
                        setPublicKey = function(pubkey) {
                            self$pubkey &lt;- pubkey
                        },
                        setPrivateKey = function(privkey) {
                            private$privkey &lt;- privkey
                        },
                        ## Make me master
                        makeMeMaster = function() {
                            private$iAmMaster &lt;- TRUE
                        },
                        ## add neg log lik and forward to next site
                        addNLLAndForward = function(beta, enc.offset) {
                            if (private$iAmMaster) {
                                ## We are master, so don&#39;t forward
                                ## Just store intermediate result and return
                                private$intermediateResult &lt;- enc.offset
                            } else {
                                ## We are workers, so add and forward
                                ## add negative log likelihood and forward result to next site
                                ## Note that offset is encrypted
                                nllValue &lt;- self$nLL(beta)
                                result.int &lt;- floor(nllValue)
                                result.frac &lt;- nllValue - result.int
                                result.fracnum &lt;- as.bigq(numerator(as.bigq(result.frac) * self$den))
                                pubkey &lt;- self$pubkey
                                enc.result.int &lt;- pubkey$encrypt(result.int)
                                enc.result.fracnum &lt;- pubkey$encrypt(result.fracnum)
                                result &lt;- list(int = pubkey$add(enc.result.int, enc.offset$int),
                                               frac = pubkey$add(enc.result.fracnum, enc.offset$frac))
                                private$nextSite$addNLLAndForward(beta, enc.offset = result)
                            }
                            ## Return a TRUE result for now.
                            TRUE
                        },
                        ## Set the next site in the communication graph
                        setNextSite = function(nextSite) {
                            private$nextSite &lt;- nextSite
                        },
                        ## The negative log likelihood
                            nLL = function(beta) {
                            if (private$iAmMaster) {
                                ## We&#39;re master, so need to get result from sites
                                ## 1. Generate a random offset and encrypt it
                                pubkey &lt;- self$pubkey
                                offset &lt;- list(int = random.bigz(nBits = 256),
                                               frac = random.bigz(nBits = 256))
                                enc.offset &lt;- list(int = pubkey$encrypt(offset$int),
                                                   frac = pubkey$encrypt(offset$frac))
                                ## 2. Send off to next site
                                throwaway &lt;- private$nextSite$addNLLAndForward(beta, enc.offset)
                                ## 3. When the call returns, the result will be in
                                ##    the field intermediateResult, so decrypt that.
                                sum &lt;- private$intermediateResult
                                privkey &lt;- private$privkey
                                intResult &lt;- as.double(privkey$decrypt(sum$int) - offset$int)
                                fracResult &lt;- as.double(as.bigq(privkey$decrypt(sum$frac) - offset$frac) / den)
                                intResult + fracResult
                            } else {
                                ## We&#39;re worker, so compute local negative log likelihood
                                tryCatch({
                                    m &lt;- coxph(formula = Surv(time, event) ~ sex + age + bm,
                                                         data = private$data,
                                                         init = beta,
                                                         control = private$cph.control)
                                    -(m$loglik[1])
                                },
                                error = function(e) NA)
                            }
                        })
                    )</code></pre>
<p>We are now ready to use our sites in the computation.</p>
<section id="generate-public-and-private-key-pair" class="level3">
<h3>1. Generate public and private key pair</h3>
<p>We also choose a denominator for all our rational approximations.</p>
<pre class="r"><code>keys &lt;- PaillierKeyPair$new(1024) ## Generate new public and private key.
den &lt;- gmp::as.bigq(2)^256  #Our denominator for rational approximations</code></pre>
</section>
<section id="create-sites" class="level3">
<h3>2. Create sites</h3>
<pre class="r"><code>site1 &lt;- Site$new(name = &quot;Site 1&quot;, data = coxData[[1]], den = den)
site2 &lt;- Site$new(name = &quot;Site 2&quot;, data = coxData[[2]], den = den)
site3 &lt;- Site$new(name = &quot;Site 3&quot;, data = coxData[[3]], den = den)</code></pre>
<p>The master process is also a site but has no data. So has to be thus designated.</p>
<pre class="r"><code>## Master has no data!
master &lt;- Site$new(name = &quot;Master&quot;, data = c(), den = den)
master$makeMeMaster()</code></pre>
</section>
<section id="distribute-public-key-to-sites" class="level3">
<h3>2. Distribute public key to sites</h3>
<pre class="r"><code>site1$setPublicKey(keys$pubkey)
site2$setPublicKey(keys$pubkey)
site3$setPublicKey(keys$pubkey)
master$setPublicKey(keys$pubkey)</code></pre>
<p>Only master has private key for decryption.</p>
<pre class="r"><code>master$setPrivateKey(keys$getPrivateKey())</code></pre>
</section>
<section id="define-the-communication-graph" class="level3">
<h3>3. Define the communication graph</h3>
<p>Master will always send to the first site, and then the others have to forward results in turn with the last site returning to the master.</p>
<pre class="r"><code>master$setNextSite(site1)
site1$setNextSite(site2)
site2$setNextSite(site3)
site3$setNextSite(master)</code></pre>
</section>
<section id="perform-the-likelihood-estimation" class="level3">
<h3>4. Perform the likelihood estimation</h3>
<pre class="r"><code>library(stats4)
nll &lt;- function(age, sex, bm) master$nLL(c(age, sex, bm))
fit &lt;- mle(nll, start = list(age = 0, sex = 0, bm = 0))</code></pre>
</section>
<section id="compare-the-results" class="level3">
<h3>5. Compare the results</h3>
<p>The summary will show the results, but only the coefficients and the standard errors.</p>
<pre class="r"><code>summary(fit)</code></pre>
<pre><code>## Maximum likelihood estimation
## 
## Call:
## mle(minuslogl = nll, start = list(age = 0, sex = 0, bm = 0))
## 
## Coefficients:
##         Estimate  Std. Error
## age -0.179585179 0.050694606
## sex  0.020087782 0.002859509
## bm   0.006815326 0.025006028
## 
## -2 log L: 19127.35</code></pre>
<p>Let us recreate a summary table similar to what would be produced by the <code>summary</code> call on the aggregated model, for comparison.</p>
<pre class="r"><code>ourSummary &lt;- function(fit) {
    coefs &lt;- coef(fit)
    se &lt;- sqrt(diag(vcov(fit)))
    expCoef &lt;- exp(coefs)
    zScore &lt;- coefs / se
    pValue &lt;- 2 * pnorm(abs(coefs / se), lower.tail = FALSE)
    result &lt;- cbind(coefs, expCoef, se, zScore, pValue)
    colnames(result) &lt;- c(&quot;coef&quot;, &quot;exp(coef)&quot;, &quot;se(coef)&quot;, &quot;z&quot;, &quot;Pr(&gt;|z|)&quot;)
    result
}
print(ourSummary(fit), digits = 4)</code></pre>
<pre><code>##          coef exp(coef) se(coef)       z  Pr(&gt;|z|)
## age -0.179585    0.8356  0.05069 -3.5425 3.964e-04
## sex  0.020088    1.0203  0.00286  7.0249 2.142e-12
## bm   0.006815    1.0068  0.02501  0.2725 7.852e-01</code></pre>
<p>Note how the estimated coefficients and standard errors closely match the full model summary below.</p>
<pre class="r"><code>summary(aggModel)</code></pre>
<pre><code>## Call:
## coxph(formula = Surv(time, event) ~ sex + age + bm + strata(stratum), 
##     data = do.call(rbind, coxData))
## 
##   n= 3000, number of events= 1588 
## 
##          coef exp(coef)  se(coef)      z Pr(&gt;|z|)    
## sex -0.179585  0.835617  0.050695 -3.542 0.000396 ***
## age  0.020088  1.020291  0.002859  7.025 2.14e-12 ***
## bm   0.006815  1.006839  0.025006  0.273 0.785204    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##     exp(coef) exp(-coef) lower .95 upper .95
## sex    0.8356     1.1967    0.7566    0.9229
## age    1.0203     0.9801    1.0146    1.0260
## bm     1.0068     0.9932    0.9587    1.0574
## 
## Concordance= 0.563  (se = 0.013 )
## Rsquare= 0.02   (max possible= 0.998 )
## Likelihood ratio test= 61.89  on 3 df,   p=2.323e-13
## Wald test            = 61.71  on 3 df,   p=2.528e-13
## Score (logrank) test = 62.04  on 3 df,   p=2.156e-13</code></pre>
<p>And the log likelihood of the distributed homomorphic fit also matches as the following computation shows.</p>
<pre class="r"><code>## -2 Log L
-2 * logLik(fit)</code></pre>
<pre><code>## &#39;log Lik.&#39; 19127.35 (df=3)</code></pre>
</section>
</section>
<section id="other-topologies" class="level2">
<h2>Other Topologies</h2>
<p>Another communication strategy is to pair each worker with a neighbor.</p>
<ul>
<li>Each site <span class="math inline">\(i\)</span> sends <span class="math inline">\(E(l_i + r_i)\)</span> and <span class="math inline">\(E(l_i - r_i)\)</span> to its neighbor workers.</li>
<li>In a synchronization step, all workers sum up what they got from their neighbors.</li>
<li>Master then queries each worker which responds the sum.</li>
<li>Master sums all of these together.</li>
</ul>
</section>
<section id="references" class="level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-survival-book">
<p>Terry M. Therneau, and Patricia M. Grambsch. 2000. <em>Modeling Survival Data: Extending the Cox Model</em>. New York: Springer-Verlag.</p>
</div>
</div>
</section>
</section>
