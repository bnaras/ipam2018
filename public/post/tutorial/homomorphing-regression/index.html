<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head lang="en-us">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />
	<meta name="description" content="Algorithmic Challenges in Protecting Privacy for Biomedical Data">
	<meta name="generator" content="Hugo 0.30.2" />
	
	<title>Homomorphic Linear Regression &mdash; IPAM 2018 Workshop</title>
	
	<link rel="stylesheet" href="/css/alabaster.css" type="text/css" />
	<link rel="stylesheet" href="/css/pygments.css" type="text/css" />

	

	<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"/>
</head>

	<body role="document">
		<div class="document">
			<div class="documentwrapper">
				<div class="bodywrapper">
					<div class="body" role="main">
						
	<h1>Homomorphic Linear Regression</h1>
	
	<section id="note" class="level2">
<h2>Note</h2>
<p>This example was communicated to me by Kee Siong Ng. I have adapted it for use here.</p>
</section>
<section id="a-synthetic-data-set" class="level2">
<h2>A Synthetic Data Set</h2>
<pre class="r"><code>n &lt;- 50
x1 = 11:(10+n)
x2 = runif(n,5,95)
x3 = rbinom(n,1,0.5)

x = data.frame(x1,x2,x3)
x = scale(x)
x = data.frame(1,x)    # the intercept is handled using a column of 1&#39;s

sigma = 1.4
eps = rnorm(x1, 0, sigma)  # generate noise vector

b = c(17, -2.5, 0.5,-5.2)   # the real model coefficient

y = b[1] + b[2] * x[,2] + b[3] * x[,3] + b[4] * x[,4] + scale(eps)  # target variable

##############################################################################
# Batch Gradient Descent algorithm, here for benchmarking and error checking
# For a refresher on the algorithm, read the first 6 pages of
#    http://cs229.stanford.edu/notes/cs229-notes1.pdf
##############################################################################

lm_sgd &lt;- function(iter, rate) {
  theta = c(0,0,0,0)
  alpha = rate
  for (iter in 1:iter) {
     adj = c(0,0,0,0)
     for (i in 1:4) {
         for (j in 1:n) {
             adj[i] = adj[i] + (sum(x[j,] * theta) - y[j]) * x[j,i]
         }
         # theta[i] = theta[i] - (alpha / n) * adj[i]         # adjust as we go is faster
     }
     for (i in 1:4) theta[i] = theta[i] - (alpha / n) * adj[i]
     print(adj)
  }
  print(theta)
}

lm_sgd(100, 0.1)</code></pre>
<pre><code>## [1] -850.00000  108.27887  -43.77564  249.39797
## [1] -765.00000   98.51090  -38.02281  225.24586
## [1] -688.50000   89.62567  -32.97204  203.44147
## [1] -619.65000   81.54323  -28.54139  183.75577
## [1] -557.68500   74.19091  -24.65821  165.98214
## [1] -501.91650   67.50262  -21.25811  149.93419
## [1] -451.72485   61.41827  -18.28403  135.44375
## [1] -406.55237   55.88322  -15.68543  122.35910
## [1] -365.89713   50.84778  -13.41754  110.54335
## [1] -329.30742   46.26677  -11.44077   99.87300
## [1] -296.37667   42.09911   -9.72006   90.23660
## [1] -266.739007   38.307435   -8.224427   81.533587
## [1] -240.065106   34.857761   -6.926474   73.673207
## [1] -216.058595   31.719189   -5.801999   66.573572
## [1] -194.45274   28.86361   -4.82963   60.16078
## [1] -175.007462   26.265476   -3.990503   54.368123
## [1] -157.50672   23.90153   -3.26798   49.13541
## [1] -141.756044   21.750629   -2.647391   44.408307
## [1] -127.580440   19.793544   -2.115811   40.137772
## [1] -114.82240   18.01278   -1.66186   36.27954
## [1] -103.340156   16.392434   -1.275526   32.793643
## [1] -93.0061408  14.9180276  -0.9480033  29.6440190
## [1] -83.7055267  13.5763982  -0.6715565  26.7980994
## [1] -75.3349740  12.3555713  -0.4393946  24.2264858
## [1] -67.8014766  11.2446541  -0.2455607  21.9026359
## [1] -61.02132895  10.23373774  -0.08483435  19.80258541
## [1] -54.91919606   9.31380803   0.04735505  17.90469670
## [1] -49.4272765   8.4766647   0.1550051  16.1894321
## [1] -44.4845488   7.7148478   0.2416082  14.6391495
## [1] -40.0360939   7.0215705   0.3102122  13.2379174
## [1] -36.0324845   6.3906586   0.3634733  11.9713487
## [1] -32.4292361   5.8164948   0.4037034  10.8264507
## [1] -29.1863125   5.2939685   0.4329116   9.7914886
## [1] -26.2676812   4.8184300   0.4528414   8.8558642
## [1] -23.640913   4.385649   0.465003   8.010005
## [1] -21.2768218   3.9917767   0.4707019   7.2452639
## [1] -19.1491396   3.6333108   0.4710649   6.5538309
## [1] -17.2342257   3.3070651   0.4670615   5.9286505
## [1] -15.5108031   3.0101403   0.4595248   5.3633488
## [1] -13.9597228   2.7398984   0.4491678   4.8521678
## [1] -12.5637505   2.4939389   0.4365994   4.3899052
## [1] -11.3073755   2.2700779   0.4223376   3.9718607
## [1] -10.1766379   2.0663277   0.4068215   3.5937877
## [1] -9.1589741  1.8808800  0.3904214  3.2518487
## [1] -8.2430767  1.7120889  0.3734483  2.9425764
## [1] -7.4187690  1.5584571  0.3561615  2.6628373
## [1] -6.6768921  1.4186218  0.3387761  2.4097999
## [1] -6.0092029  1.2913428  0.3214688  2.1809050
## [1] -5.4082826  1.1754917  0.3043833  1.9738399
## [1] -4.8674544  1.0700415  0.2876351  1.7865142
## [1] -4.3807089  0.9740576  0.2713156  1.6170385
## [1] -3.9426380  0.8866895  0.2554956  1.4637051
## [1] -3.5483742  0.8071632  0.2402284  1.3249701
## [1] -3.1935368  0.7347743  0.2255525  1.1994380
## [1] -2.8741831  0.6688816  0.2114941  1.0858474
## [1] -2.5867648  0.6089017  0.1980690  0.9830575
## [1] -2.3280883  0.5543037  0.1852841  0.8900373
## [1] -2.0952795  0.5046043  0.1731394  0.8058544
## [1] -1.8857515  0.4593636  0.1616290  0.7296658
## [1] -1.6971764  0.4181814  0.1507423  0.6607093
## [1] -1.5274588  0.3806933  0.1404650  0.5982957
## [1] -1.3747129  0.3465677  0.1307797  0.5418015
## [1] -1.2372416  0.3155028  0.1216669  0.4906631
## [1] -1.1135174  0.2872240  0.1131054  0.4443707
## [1] -1.0021657  0.2614811  0.1050727  0.4024632
## [1] -0.90194912  0.23804662  0.09754578  0.36452365
## [1] -0.8117542  0.2167135  0.0905011  0.3301748
## [1] -0.73057879  0.19729306  0.08391502  0.29907538
## [1] -0.65752091  0.17961382  0.07776401  0.27091684
## [1] -0.59176882  0.16351954  0.07202489  0.24541993
## [1] -0.53259194  0.14886805  0.06667493  0.22233205
## [1] -0.4793327  0.1355299  0.0616920  0.2014247
## [1] -0.43139947  0.12338739  0.05705464  0.18249108
## [1] -0.38825952  0.11233320  0.05274217  0.16534414
## [1] -0.34943357  0.10226976  0.04873471  0.14981461
## [1] -0.31449021  0.09310823  0.04501320  0.13574932
## [1] -0.28304119  0.08476774  0.04155949  0.12300964
## [1] -0.25473707  0.07717467  0.03835624  0.11147017
## [1] -0.22926336  0.07026200  0.03538704  0.10101737
## [1] -0.20633703  0.06396875  0.03263629  0.09154851
## [1] -0.18570333  0.05823938  0.03008928  0.08297061
## [1] -0.16713299  0.05302334  0.02773209  0.07519950
## [1] -0.15041969  0.04827463  0.02555162  0.06815900
## [1] -0.13537772  0.04395135  0.02353556  0.06178016
## [1] -0.12183995  0.04001537  0.02167232  0.05600055
## [1] -0.10965596  0.03643199  0.01995104  0.05076367
## [1] -0.09869036  0.03316960  0.01836155  0.04601834
## [1] -0.08882132  0.03019944  0.01689432  0.04171825
## [1] -0.07993919  0.02749532  0.01554044  0.03782147
## [1] -0.07194527  0.02503340  0.01429161  0.03429003
## [1] -0.06475075  0.02279199  0.01314006  0.03108953
## [1] -0.05827567  0.02075132  0.01207858  0.02818885
## [1] -0.05244810  0.01889341  0.01110041  0.02555980
## [1] -0.04720329  0.01720189  0.01019930  0.02317684
## [1] -0.042482964  0.015661853  0.009369424  0.021016850
## [1] -0.03823467  0.01425972  0.00860536  0.01905889
## [1] -0.034411201  0.012983151  0.007902084  0.017283988
## [1] -0.030970081  0.011820889  0.007254929  0.015674970
## [1] -0.027873073  0.010762697  0.006659568  0.014216274
## [1] -0.025085766  0.009799256  0.006111991  0.012893802
## [1] 16.9995485 -2.4039554  0.5763752 -5.1703591</code></pre>
<pre class="r"><code>##########################################################################################
# Distributed Privacy-Preserving Gradient Descent algorithm for Linear Regression
##########################################################################################
# Basic setup:
# FIU holds the vector y of true labels
# RE1 holds the data x[,1:3]
# RE2 holds the data x[,4]
# Together, they want to learn a linear model to predict y using x but in such a way that
# - nobody sees each other&#39;s data,
# - RE1 holds the coefficients for the variables it holds, which is not visible to others
# - RE2 holds the coefficients for the variables it holds, which is not visible to others
# - Prediction of a new instance requires the collaboration of RE1 and RE2
###########################################################################################

###############################################################################################
# FIU first generates a public-private key pair using the Paillier scheme
# Public key is used by RE1 and RE2 to encrypt their data and do maths on them.
# Private key is visible only to FIU and is used by the FIU to decrypt data sent from the REs.
###########

library(homomorpheR)

keypair = PaillierKeyPair$new(modulusBits = 1024)
pubkey = keypair$pubkey
privkey = keypair$getPrivateKey()

# Convenience function
zipf = function(x1,x2,x3) {
  res = c()
  for (i in 1:length(x1)) res = c(res,x1[i],x2[i],x3[i])
  res
}

# zipf(5,10,1)
# zipf(c(1,2,3), c(4,5,6), c(1,1,1))

######################################################################
# Paillier is defined only on positive integers.
# We approximate a floating point number X by 3 integers (a,b,c)
# such that X is approximately equal to (a + b/largenum) / 10^c
#
# Example: Assuming largenum = 2^10, 5.2 can be represented by
#  (5, 204, 0) = (5 + 204/1024) / 1 = 5.19922
#  or (50, 2040, 1) = (50 + 2040/1024) / 10 = 5.19922
#
# In general, the larger largenum is, the better the approximation.
#################

largenum = 2^50
encodeFloat = function(x, e=0) {
  x = x * 10^e
  x1 = floor(x)
  x2 = x - x1
  x2 = floor(x2 * largenum)
  exps = rep(e, length(x))
  zipf(x1,x2,exps)
}

# encodeFloat(5.2)
# encodeFloat(5.2, 2)
# encodeFloat(c(4.5,5.2,7), 1)

# Some useful constants
zero = pubkey$encrypt(&#39;0&#39;)
one = pubkey$encrypt(&#39;1&#39;)

############################################################################
# We encrypt each number (a,b,c) by encrypting a and b with the public key
# The input can be a vector of numbers
################

encrypt = function(z, e=0) {
  y = encodeFloat(z, e)
  res = rep(zero, length(y))
  for (i in 1:length(y)) {
      if (i %% 3 == 0) { res[i] = y[i] }
      else { res[i] = pubkey$encrypt(as.character(y[i])) }
  }
  res
}

############################################################################
# We decrypt each encrypted number (enc(a), enc(b),c) using the private key
# by computing (dec(enc(a)) + dec(enc(b))/largenum) / 10^c
# The input can be a vector of numbers.
# We need to deal with negative numbers too.
##################

decrypt = function(en) {
  uen = en
  for (i in 1:length(uen)) {
      if (i %% 3 != 0) uen[i] = privkey$decrypt(en[i])
  }
  # deal with negative results;
  # see https://crypto.stackexchange.com/questions/19457/how-can-i-do-minus-on-plaintexts-in-the-paillier-cryptosystem
  for (i in 1:length(uen)) {
    if (i %% 3 != 0 &amp;&amp;    # don&#39;t process exponents
        uen[i] &gt;= as.double(pubkey$n/3.0)) { uen[i] = uen[i] - pubkey$n }
  }
  res = c()
  for (i in seq(1, length(uen), 3)) {
      res = c(res,
             (as.double(uen[i]) + as.double(uen[i+1]/(largenum))) / as.double(10^uen[i+2]))
  }
  return(res)
}

# decrypt(encrypt(4.7))
# decrypt(encrypt(0.5))
# decrypt(encrypt(-2.3))
# (z = encrypt(c(5.2,4.7,-2.6)))
# decrypt(z)

############################################################################
# We next define addition of two encrypted numbers: (enc(a1), enc(b1), c1) and (enc(a2), enc(b2), c2).
# Addition can be done on the encrypted a&#39;s and encrypted b&#39;s if c1 = c2. We make c1 = c2 true by
# multiplying by powers of 10 when necessary.
# The need to make c1 = c2 is the reason why we can&#39;t have c1 and c2 encrypted.
# The function works on vectors.
###############

addenc = function(x, y) {
  res = x
  for (i in seq(1, length(x), 3)) {
       if (x[i+2] != y[i+2]) {  # if different exponent, make the exponents equal by multiplying
          res[i+2] = max(x[i+2], y[i+2])
          xdiff = res[i+2] - x[i+2]
          ydiff = res[i+2] - y[i+2]
          if (xdiff &gt; 0) {
              x[i] = pubkey$mult(x[i], 10^(xdiff))
              x[i+1] = pubkey$mult(x[i+1], 10^(xdiff))
          }
          if (ydiff &gt; 0) {
              y[i] = pubkey$mult(y[i], 10^(ydiff))
              y[i+1] = pubkey$mult(y[i+1], 10^(ydiff))
          }
       }
       res[i] = pubkey$add(x[i], y[i])
       # print(privkey$decrypt(c(x[i], y[i], res[i])))
       res[i+1] = pubkey$add(x[i+1], y[i+1])
  }
  res
}

############################################################################
# We next define subtraction of two encrypted numbers: (enc(a1), enc(b1), c1) and (enc(a2), enc(b2), c2).
# We simply multiply the second encrypted number by -1 and then add it to the first encrypted number.
############

subenc = function(x, y) {
  for (i in seq(1, length(x), 3)) {
      # y[i:i+1] = pubkey$mult(y[i:i+1], -1)  # this doesn&#39;t work, why?
      y[i] = pubkey$mult(y[i], -1)
      y[i+1] = pubkey$mult(y[i+1], -1)
  }
  addenc(x, y)
}

#############################################################################################
# We next define the multiplication of an encrypted number en = (enc(a),enc(b),c) by a scalar y
# Again, Paillier only allows y to be an integer. To deal with floating point numbers, we use
# en * y = en * (y_int + y_frac)
#        = en * y_int + (enc(a) * floor(y_frac * 10^n), enc(b) * floor(y_frac * 10^n), n)
# where n is a parameter with larger n leading to better approximation. We use n = 3 below.
#######

smultenc = function(x,y) {
  yint = floor(y * 1000)
  res = x
  for (i in seq(1, length(x), 3)) {
      res[i] = pubkey$mult(x[i], yint)
      res[i+1] = pubkey$mult(x[i+1], yint)
      res[i+2] =  x[i+2] + 3
  }
  res
}

################
# Here are some test cases
####
# five = encrypt(5.4)
# ten = encrypt(10.2)
# five
# ten
# decrypt(addenc(five,ten))
# decrypt(subenc(ten,five))
# decrypt(subenc(five,ten))
# decrypt(addenc(c(five,ten), c(ten,ten)))
#
# five = encrypt(5.4,1)
# ten = encrypt(10.2,2)
# decrypt(addenc(five,ten))
# decrypt(subenc(ten,five))
# decrypt(addenc(c(five,ten), c(ten,ten)))
#
# decrypt(smultenc(five, 4))
# decrypt(smultenc(ten, 6))
# decrypt(smultenc(c(five,ten), 4))
# decrypt(smultenc(c(five,ten), -4))

##################################################################
# Here are the functions to setup the parties in the computation
#################

x1 = c()  # these 3 vectors belong to RE1
x2 = c()
x3 = c()

re1setup = function() {
  x1 &lt;&lt;- encrypt(x[,1])
  x2 &lt;&lt;- encrypt(x[,2])
  x3 &lt;&lt;- encrypt(x[,3])
}

x4 = c() # this belong to RE2

re2setup = function() {
  x4 &lt;&lt;- encrypt(x[,4])
}

mastersetup = function() {
  re1setup()
  re2setup()
}

############
# This function computes the gradient: the difference between predicted values (encrypted) by REs and the true values
# Note the gradient is unencrypted. We could encrypt it if necessary.
#########

master_grad &lt;- function(x) {
  xd = decrypt(x)
  xd - y
  # subenc(xd, y)
}

###########
# This is used to compute the partial predictions based on RE1&#39;s data only. The values are encrypted.
###########
re1pred &lt;- function() {
   # return (theta1 * x[,1] + theta2 * x[,2] + theta3 * x[,3])
  return (addenc(smultenc(x1, theta1),
          addenc(smultenc(x2, theta2),
                 smultenc(x3, theta3)))
          )
}

#############
# Here, RE2 takes the partial prediction of RE1 and then add its contribution to the prediction.
# The final prediction values are encrypted.
###########

re2pred &lt;- function(z) {
   # return (z + theta4 * x[,4])
  return (addenc(z, smultenc(x4, theta4)))
}

cadj = c(0,0,0,0) # a variable we want to print to keep track of progress

#############
# This is RE1&#39;s model update function and implements the gradient descent update formula.
# It takes the gradient (unencrypted) from the master and then adjust its own theta.
# The whole computation is assumed to take place within RE1 and no encryption is required.
# We can encrypt the whole thing if we want to.
###########

re1update &lt;- function(z) {
   theta1 &lt;&lt;- theta1 - (alpha / n) * sum(z * x[,1])
   theta2 &lt;&lt;- theta2 - (alpha / n) * sum(z * x[,2])
   theta3 &lt;&lt;- theta3 - (alpha / n) * sum(z * x[,3])
   cadj[1] &lt;&lt;- sum(z * x[,1])
   cadj[2] &lt;&lt;- sum(z * x[,2])
   cadj[3] &lt;&lt;- sum(z * x[,3])
}

#############
# This is RE2&#39;s model update function and implements the gradient descent update formula.
# It takes the gradient (unencrypted) from the master and then adjust its own theta.
# The whole computation is assumed to take place within RE1 and no encryption is required.
# We can encrypt the whole thing if we want to.
###########

re2update &lt;- function(z) {
   theta4 &lt;&lt;- theta4 - (alpha / n) * sum(z * x[,4])
   cadj[4] &lt;&lt;- sum(z * x[,4])
}

##########################################################################
# Finally, this is the privacy-preserving linear regression algorithm.
# The algorithm can be sensitive to the learning rate.
##########################################################################

pp_lm_sgd &lt;- function(iter, rate) {

  theta1 &lt;&lt;- 0
  theta2 &lt;&lt;- 0
  theta3 &lt;&lt;- 0
  theta4 &lt;&lt;- 0
  alpha &lt;&lt;- rate

  mastersetup()  # encrypt the data and set up communication

  for (i in 1:iter) {
      p1 = re1pred()     # partial prediction
      px = re2pred(p1)   # full prediction
      grad = master_grad(px)  # compute gradient based on difference between true values and predicted values
      re1update(grad)    # update models independently
      re2update(grad)
      print(cadj)
  }
  print(c(theta1,theta2,theta3,theta4))
}

model0 = lm_sgd(100, 0.1)</code></pre>
<pre><code>## [1] -850.00000  108.27887  -43.77564  249.39797
## [1] -765.00000   98.51090  -38.02281  225.24586
## [1] -688.50000   89.62567  -32.97204  203.44147
## [1] -619.65000   81.54323  -28.54139  183.75577
## [1] -557.68500   74.19091  -24.65821  165.98214
## [1] -501.91650   67.50262  -21.25811  149.93419
## [1] -451.72485   61.41827  -18.28403  135.44375
## [1] -406.55237   55.88322  -15.68543  122.35910
## [1] -365.89713   50.84778  -13.41754  110.54335
## [1] -329.30742   46.26677  -11.44077   99.87300
## [1] -296.37667   42.09911   -9.72006   90.23660
## [1] -266.739007   38.307435   -8.224427   81.533587
## [1] -240.065106   34.857761   -6.926474   73.673207
## [1] -216.058595   31.719189   -5.801999   66.573572
## [1] -194.45274   28.86361   -4.82963   60.16078
## [1] -175.007462   26.265476   -3.990503   54.368123
## [1] -157.50672   23.90153   -3.26798   49.13541
## [1] -141.756044   21.750629   -2.647391   44.408307
## [1] -127.580440   19.793544   -2.115811   40.137772
## [1] -114.82240   18.01278   -1.66186   36.27954
## [1] -103.340156   16.392434   -1.275526   32.793643
## [1] -93.0061408  14.9180276  -0.9480033  29.6440190
## [1] -83.7055267  13.5763982  -0.6715565  26.7980994
## [1] -75.3349740  12.3555713  -0.4393946  24.2264858
## [1] -67.8014766  11.2446541  -0.2455607  21.9026359
## [1] -61.02132895  10.23373774  -0.08483435  19.80258541
## [1] -54.91919606   9.31380803   0.04735505  17.90469670
## [1] -49.4272765   8.4766647   0.1550051  16.1894321
## [1] -44.4845488   7.7148478   0.2416082  14.6391495
## [1] -40.0360939   7.0215705   0.3102122  13.2379174
## [1] -36.0324845   6.3906586   0.3634733  11.9713487
## [1] -32.4292361   5.8164948   0.4037034  10.8264507
## [1] -29.1863125   5.2939685   0.4329116   9.7914886
## [1] -26.2676812   4.8184300   0.4528414   8.8558642
## [1] -23.640913   4.385649   0.465003   8.010005
## [1] -21.2768218   3.9917767   0.4707019   7.2452639
## [1] -19.1491396   3.6333108   0.4710649   6.5538309
## [1] -17.2342257   3.3070651   0.4670615   5.9286505
## [1] -15.5108031   3.0101403   0.4595248   5.3633488
## [1] -13.9597228   2.7398984   0.4491678   4.8521678
## [1] -12.5637505   2.4939389   0.4365994   4.3899052
## [1] -11.3073755   2.2700779   0.4223376   3.9718607
## [1] -10.1766379   2.0663277   0.4068215   3.5937877
## [1] -9.1589741  1.8808800  0.3904214  3.2518487
## [1] -8.2430767  1.7120889  0.3734483  2.9425764
## [1] -7.4187690  1.5584571  0.3561615  2.6628373
## [1] -6.6768921  1.4186218  0.3387761  2.4097999
## [1] -6.0092029  1.2913428  0.3214688  2.1809050
## [1] -5.4082826  1.1754917  0.3043833  1.9738399
## [1] -4.8674544  1.0700415  0.2876351  1.7865142
## [1] -4.3807089  0.9740576  0.2713156  1.6170385
## [1] -3.9426380  0.8866895  0.2554956  1.4637051
## [1] -3.5483742  0.8071632  0.2402284  1.3249701
## [1] -3.1935368  0.7347743  0.2255525  1.1994380
## [1] -2.8741831  0.6688816  0.2114941  1.0858474
## [1] -2.5867648  0.6089017  0.1980690  0.9830575
## [1] -2.3280883  0.5543037  0.1852841  0.8900373
## [1] -2.0952795  0.5046043  0.1731394  0.8058544
## [1] -1.8857515  0.4593636  0.1616290  0.7296658
## [1] -1.6971764  0.4181814  0.1507423  0.6607093
## [1] -1.5274588  0.3806933  0.1404650  0.5982957
## [1] -1.3747129  0.3465677  0.1307797  0.5418015
## [1] -1.2372416  0.3155028  0.1216669  0.4906631
## [1] -1.1135174  0.2872240  0.1131054  0.4443707
## [1] -1.0021657  0.2614811  0.1050727  0.4024632
## [1] -0.90194912  0.23804662  0.09754578  0.36452365
## [1] -0.8117542  0.2167135  0.0905011  0.3301748
## [1] -0.73057879  0.19729306  0.08391502  0.29907538
## [1] -0.65752091  0.17961382  0.07776401  0.27091684
## [1] -0.59176882  0.16351954  0.07202489  0.24541993
## [1] -0.53259194  0.14886805  0.06667493  0.22233205
## [1] -0.4793327  0.1355299  0.0616920  0.2014247
## [1] -0.43139947  0.12338739  0.05705464  0.18249108
## [1] -0.38825952  0.11233320  0.05274217  0.16534414
## [1] -0.34943357  0.10226976  0.04873471  0.14981461
## [1] -0.31449021  0.09310823  0.04501320  0.13574932
## [1] -0.28304119  0.08476774  0.04155949  0.12300964
## [1] -0.25473707  0.07717467  0.03835624  0.11147017
## [1] -0.22926336  0.07026200  0.03538704  0.10101737
## [1] -0.20633703  0.06396875  0.03263629  0.09154851
## [1] -0.18570333  0.05823938  0.03008928  0.08297061
## [1] -0.16713299  0.05302334  0.02773209  0.07519950
## [1] -0.15041969  0.04827463  0.02555162  0.06815900
## [1] -0.13537772  0.04395135  0.02353556  0.06178016
## [1] -0.12183995  0.04001537  0.02167232  0.05600055
## [1] -0.10965596  0.03643199  0.01995104  0.05076367
## [1] -0.09869036  0.03316960  0.01836155  0.04601834
## [1] -0.08882132  0.03019944  0.01689432  0.04171825
## [1] -0.07993919  0.02749532  0.01554044  0.03782147
## [1] -0.07194527  0.02503340  0.01429161  0.03429003
## [1] -0.06475075  0.02279199  0.01314006  0.03108953
## [1] -0.05827567  0.02075132  0.01207858  0.02818885
## [1] -0.05244810  0.01889341  0.01110041  0.02555980
## [1] -0.04720329  0.01720189  0.01019930  0.02317684
## [1] -0.042482964  0.015661853  0.009369424  0.021016850
## [1] -0.03823467  0.01425972  0.00860536  0.01905889
## [1] -0.034411201  0.012983151  0.007902084  0.017283988
## [1] -0.030970081  0.011820889  0.007254929  0.015674970
## [1] -0.027873073  0.010762697  0.006659568  0.014216274
## [1] -0.025085766  0.009799256  0.006111991  0.012893802
## [1] 16.9995485 -2.4039554  0.5763752 -5.1703591</code></pre>
<pre class="r"><code>model1 = pp_lm_sgd(100, 0.1)</code></pre>
<pre><code>## [1] -850.00000  108.27887  -43.77564  249.39797
## [1] -765.00000   98.49096  -38.04839  225.23784
## [1] -688.50000   89.60798  -32.99894  203.40859
## [1] -619.65000   81.53797  -28.56591  183.71651
## [1] -557.70000   74.18901  -24.68797  165.96793
## [1] -501.95000   67.46889  -21.25285  149.91822
## [1] -451.75000   61.38629  -18.30382  135.42231
## [1] -406.55000   55.89144  -15.68582  122.32956
## [1] -365.90000   50.84392  -13.43692  110.55021
## [1] -329.30000   46.24743  -11.45151   99.88443
## [1] -296.400000   42.106164   -9.725777   90.234236
## [1] -266.750000   38.277348   -8.248811   81.507934
## [1] -240.100000   34.856360   -6.925432   73.648500
## [1] -216.050000   31.702772   -5.793741   66.566158
## [1] -194.450000   28.869794   -4.852283   60.160802
## [1] -175.00000   26.25681   -3.99643   54.38383
## [1] -157.500000   23.870389   -3.271365   49.139143
## [1] -141.750000   21.757172   -2.630451   44.422734
## [1] -127.600000   19.776731   -2.111788   40.144825
## [1] -114.850000   18.026809   -1.669191   36.250298
## [1] -103.350000   16.407301   -1.299846   32.792363
## [1] -93.0000000  14.9221616  -0.9490294  29.6221118
## [1] -83.7000000  13.5716469  -0.6676493  26.7904528
## [1] -75.3500000  12.3578620  -0.4537981  24.2483858
## [1] -67.8000000  11.2336563  -0.2522993  21.8981084
## [1] -61.05000000  10.24592448  -0.06742166  19.78651540
## [1] -54.95000000   9.29902764   0.05655682  17.91972479
## [1] -49.4500000   8.4928152   0.1677294  16.1936186
## [1] -44.5000000   7.7316481   0.2218182  14.6143147
## [1] -40.0500000   7.0086991   0.3149154  13.2269981
## [1] -36.0500000   6.3797956   0.3485677  11.9843786
## [1] -32.4500000   5.7933206   0.4250438  10.8357464
## [1] -29.2000000   5.3029962   0.4439826   9.7828113
## [1] -26.2500000   4.8063562   0.4571985   8.8768762
## [1] -23.6500000   4.4056110   0.4637848   8.0157307
## [1] -21.2500000   4.0006553   0.4665558   7.2525852
## [1] -19.1500000   3.6425944   0.4650583   6.5363345
## [1] -17.2500000   3.2803232   0.4597454   5.9180839
## [1] -15.500000   3.013947   0.447803   5.344623
## [1] -13.9500000   2.7433598   0.4320452   4.8691616
## [1] -12.5500000   2.4727728   0.4162875   4.3937005
## [1] -11.3000000   2.2467197   0.4452612   3.9632265
## [1] -10.2000000   2.0699224   0.4209662   3.5815550
## [1] -9.1500000  1.8910199  0.3947636  3.2488835
## [1] -8.2500000  1.7100121  0.3666534  2.9652119
## [1] -7.4000000  1.5780044  0.3361821  2.6794352
## [1] -6.7000000  1.3946356  0.3570719  2.3938560
## [1] -6.000000  1.309523  0.322332  2.154974
## [1] -5.4000000  1.1733045  0.2880455  1.9671973
## [1] -4.8500000  1.0837254  0.3003981  1.7754078
## [1] -4.4000000  0.9454020  0.2642039  1.6366310
## [1] -3.9500000  0.9048228  0.2741954  1.4427362
## [1] -3.5500000  0.8154994  0.2356403  1.3018543
## [1] -3.2000000  0.7217099  0.2441776  1.2080647
## [1] -2.8500000  0.6813865  0.2032615  1.0650775
## [1] -2.6000000  0.5875969  0.2117987  0.9712879
## [1] -2.3500000  0.5451683  0.1689750  0.8773008
## [1] -2.1000000  0.4982735  0.1732436  0.8304060
## [1] -1.9000000  0.4534840  0.1794199  0.7345112
## [1] -1.7000000  0.4089502  0.1346885  0.6895240
## [1] -1.5000000  0.3641606  0.1408647  0.5936292
## [1] -1.3500000  0.3662658  0.1427724  0.5446292
## [1] -1.2500000  0.3217320  0.0980410  0.4996421
## [1] -1.1000000  0.2748372  0.1023096  0.4527473
## [1] -1.0000000  0.2769424  0.1042173  0.4037473
## [1] -0.9000000  0.2300476  0.1084859  0.3568525
## [1] -0.8000000  0.2321528  0.1103935  0.3078525
## [1] -0.75000000  0.18551383  0.06375452  0.31186534
## [1] -0.65000000  0.18761904  0.06566214  0.26286534
## [1] -0.60000000  0.13861904  0.06802314  0.26497055
## [1] -0.55000000  0.14072425  0.06993077  0.21597055
## [1] -0.50000000  0.14072425  0.06993077  0.21597055
## [1] -0.4500000  0.1428295  0.0718384  0.1669705
## [1] -0.40000000  0.09619046  0.02519940  0.17098338
## [1] -0.35000000  0.09619046  0.02519940  0.17098338
## [1] -0.30000000  0.09829567  0.02710703  0.12198338
## [1] -0.30000000  0.09829567  0.02710703  0.12198338
## [1] -0.25000000  0.09829567  0.02710703  0.12198338
## [1] -0.20000000  0.04929567  0.02946803  0.12408859
## [1] -0.20000000  0.05140088  0.03137565  0.07508859
## [1] -0.20000000  0.05140088  0.03137565  0.07508859
## [1] -0.15000000  0.05140088  0.03137565  0.07508859
## [1] -0.15000000  0.05140088  0.03137565  0.07508859
## [1] -0.15000000  0.05140088  0.03137565  0.07508859
## [1] -0.10000000  0.05140088  0.03137565  0.07508859
## [1] -0.10000000  0.05350609  0.03328328  0.02608859
## [1] -0.10000000  0.05350609  0.03328328  0.02608859
## [1] -0.10000000  0.00450609  0.03564428  0.02819380
## [1] -0.10000000  0.00450609  0.03564428  0.02819380
## [1] -0.05000000  0.00450609  0.03564428  0.02819380
## [1] -0.050000000  0.006867089 -0.013355718  0.030101432
## [1] -0.050000000  0.006867089 -0.013355718  0.030101432
## [1] -0.05000000  0.00450609  0.03564428  0.02819380
## [1] -0.050000000  0.006867089 -0.013355718  0.030101432
## [1] -0.050000000  0.006867089 -0.013355718  0.030101432
## [1] -0.050000000  0.006867089 -0.013355718  0.030101432
## [1] -0.05000000  0.00450609  0.03564428  0.02819380
## [1] -0.050000000  0.006867089 -0.013355718  0.030101432
## [1]  1.580958e-13  6.867089e-03 -1.335572e-02  3.010143e-02
## [1]  1.580958e-13  6.867089e-03 -1.335572e-02  3.010143e-02
## [1] 17.0001000 -2.4032127  0.5770222 -5.1699920</code></pre>
<pre class="r"><code>## References</code></pre>
</section>



						
					</div>
				</div>
			</div>
			
			<div class="sphinxsidebar" role="navigation" aria-label="main navigation">
	<div class="sphinxsidebarwrapper">
		<p class="logo">
			<a href="/">
				<img class="logo" src="/favicon.ico" alt="Logo"/>
				<h1 class="logo logo-name"></h1>
			</a>
		</p>
		
		<p class="blurb">Algorithmic Challenges in Protecting Privacy for Biomedical Data</p>

		

	<p>
		<iframe src="https://ghbtns.com/github-btn.html?user=bnaras&repo=ipam2018&type=watch&count=true&size=large"
		allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
	</p>

	

	
		

		

<h3>Navigation</h3>
<ul>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/index.html">Home</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="https://github.com/bnaras/ipam2018">Github</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/post/tutorial/">Tutorial</a>
	</li>
	
</ul>


		<h3>Related Topics</h3>
<ul>
  <li><a href="/">Documentation overview</a><ul>
  <li>Previous: <a href="/post/tutorial/vertical-partitioned-lasso/" title="Lasso on Vertically Partitioned Data">Lasso on Vertically Partitioned Data</a></li>
  <li>Next: <a href="/post/tutorial/homomorphing-intro/" title="Homomorphic Computations">Homomorphic Computations</a></li>
</ul>

	</div>
</div>
<div class="clearer"></div>
</div>
			<script type="text/javascript" src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


			

			

			
		</div>
	</body>
</html>